[{"content":"Been working heads down along with the team for the last couple of months. Our work is mostly around Retrieval-Augmented Generation. Personally, I had a lot of learnings around Machine Learning, especially Large Language Models like GPT.\nPart of our work was showcased at Microsoft Build 2023 (Archives for future readers). I\u0026rsquo;ve listed down sessions where our work was showcased or mentioned. I\u0026rsquo;ve also listed sessions that I really liked.\nSatya\u0026rsquo;s Keynote - Link AI dominated the keynote obviously. I recommend watching it to get a high-level idea of what\u0026rsquo;s in the store in the coming few weeks. There have been multiple teams grinding to release several features. Our team\u0026rsquo;s work is present on this slide (16:35 mark in the video):\nSpecifically these areas: Vector indexing, Retrieval Augmented Generation, Prompt workflows.\nFrom the keynote, I particularly liked this slide that has historical references that give an idea of what our understanding was of future technology back then:\nI\u0026rsquo;ve linked the first three:\nAs We May Think by Vannevar Bush, July 1945 Man-Computer Symbiosis by J. C. R. Licklider, March 1960 The Mother of All Demos by Douglas Engelbart, December 1968 Another interesting slide was a graph around GDP growth with references to revolutionary technological advancements:\nBuild and maintain your company Copilot with Azure ML and GPT-4 - Link Daniel Schneider and Seth Juarez demoed our team\u0026rsquo;s work. At 38:00 mark, Daniel shows how to create a Vector Index in PromptFlow:\nThe full session covers not just our work but also of others around us in AzureML. Great demo session overall. There was some adhoc work I did for Daniel\u0026rsquo;s Copilot demo. I created a websocket server for his Copilot, and a console client. He demoed it at 19:00 mark:\nLooking at the console client Seth remarks: \u0026ldquo;If it was 1987 and this is the interface we give to our customers\u0026hellip;\u0026rdquo; - me crying\nThe era of the AI Copilot - Link Delivered by Kevin Scott (Microsoft CTO), it explains what a Copilot is with a nice demo (code) at 35:30 mark. Greg Brockman (OpenAI Co-founder) was invited on stage for a QnA. Kevin also mentioned Harrison Chase (Creator of LangChain) who was present in the audience. Nice.\nState of GPT - Link My favorite session from the conference, delivered by Andrej Karpathy from OpenAI. I\u0026rsquo;ve been following his work for some time now. This session gives you an overview of the ecosystem that has come to exist around ChatGPT. It touches upon things like Chain-of-Thought prompting, AutoGPT, LangChain, etc. The best part is the explanation of how ChatGPT is trained. Deeply technical session. Loved it.\nBuilding AI solutions with Semantic Kernel - Link I\u0026rsquo;ve been using LangChain to write LLM based applications. Semantic Kernel by Microsoft is another alternative. A lot of overlaps between the two. Semantic Kernel was originally written in C# and has a Python package now.\nBuilding and using AI models responsibly - Link Generative models spew all kinds of things. What goes in and comes out of these models will need to be adjusted, for instance, to filter out harmful responses by LLMs. ResponsibleAI works in this area. I feel this problem is big enough that we might see startups focusing on just that.\nEnd Lot to learn.\n","permalink":"https://blog.shivammamgain.com/posts/2023/build-2023/","summary":"Microsoft Build 2023 and our team\u0026rsquo;s work","title":"//build/ 2023"},{"content":"Table-driven tests are great because they remove the need for duplicate testing setup for similar test cases. In following this approach, the input and the expected output of these test cases are conveniently placed in a list (the table).\nI’ve come across folks trying to write a table-driven test even though it increases the complexity of the test (anecdotal?). For such instances, separate tests for the test cases would’ve resulted in easier-to-understand code.\nTo demonstrate what I seen, here’s a sample HTTP handler that accepts a POST JSON request to create a TODO:\nfunc (c *Controller) CreateTODO(w http.ResponseWriter, r *http.Request) { // Is method allowed if r.Method != http.MethodPost { http.Error(w, \u0026#34;method is not POST\u0026#34;, http.StatusMethodNotAllowed) return } // Authentication call token := r.Header.Get(\u0026#34;AuthToken\u0026#34;) if !c.auth.IsAuthenticated(token) { http.Error(w, \u0026#34;unauthenticated\u0026#34;, http.StatusUnauthorized) return } // Decoding and validation todo := \u0026amp;TODO{} if err := json.NewDecoder(r.Body).Decode(todo); err != nil { http.Error(w, \u0026#34;invalid json: \u0026#34;+err.Error(), http.StatusBadRequest) return } if err := todo.Validate(); err != nil { http.Error(w, \u0026#34;invalid todo: \u0026#34;+err.Error(), http.StatusBadRequest) return } // Database call if err := c.db.CreateTODO(todo); err != nil { http.Error(w, \u0026#34;db error: \u0026#34;+err.Error(), http.StatusInternalServerError) return } respond(w, 201, \u0026#34;todo created\u0026#34;) } There are broadly 4 steps here before a TODO is considered to be successfully created:\nValidation of allowed method (POST) Authentication via an auth client Decoding of JSON from request body, and validation of fields Database INSERT call via a DB client/ORM The auth client c.auth and db client c.db are fields of the Controller struct.\ntype Controller struct { auth Authenticator db Database } type Authenticator interface { IsAuthenticated(token string) bool } type Database interface { CreateTODO(todo *TODO) error } Mocks can be generated for these interfaces to be used in unit tests.\nGood table-driven test The 3rd step (Decoding of JSON from request body, and validation of fields) from the above is a great candidate for table-driven tests because there could be multiple test inputs that can share the same testing setup. Here’s a small list of these:\nInvalid JSON in the request body Empty TODO name Empty TODO category All of these will result in Bad Requests, albeit different response bodies.\nA table-driven test for it would look something like this:\nfunc TestController_CreateTODO_BadRequestErrors(t *testing.T) { testCases := []struct { name string requestBody string expectedResponse string }{ {\u0026#34;invalid json\u0026#34;, `{\u0026#34;name\u0026#34;}`, \u0026#34;invalid json: invalid character \u0026#39;}\u0026#39; after object key\\n\u0026#34;}, {\u0026#34;empty name\u0026#34;, `{\u0026#34;name\u0026#34;: \u0026#34;\u0026#34;}`, \u0026#34;invalid todo: empty name\\n\u0026#34;}, {\u0026#34;empty category\u0026#34;, `{\u0026#34;name\u0026#34;: \u0026#34;task1\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;\u0026#34;}`, \u0026#34;invalid todo: empty category\\n\u0026#34;}, } for _, tc := range testCases { t.Run(tc.name, func(t *testing.T) { // Setup mocks c := gomock.NewController(t) defer c.Finish() auth := mock.NewMockAuthenticator(c) db := mock.NewMockDatabase(c) ctrl := api.NewController(auth, db) // Setup response recorder and request w := httptest.NewRecorder() rBody := bytes.NewBufferString(tc.requestBody) r := httptest.NewRequest(http.MethodPost, \u0026#34;http://example.com/todos\u0026#34;, rBody) r.Header.Add(\u0026#34;AuthToken\u0026#34;, testToken) // Expectations from mocks auth.EXPECT().IsAuthenticated(testToken).Return(true) // Call HTTP handler ctrl.CreateTODO(w, r) resp := w.Result() // Assertions assertEqual(t, 400, resp.StatusCode) assertEqual(t, tc.expectedResponse, responseBody(resp)) }) } } Full code for this snippet can be found in this file: controller_test.go.\nBad table-driven test If you try to write a table-driven test that covers 1st, 2nd, and 4th step, and the success case, it would look like this:\nfunc TestController_CreateTODO_BadTableDrivenTest(t *testing.T) { testCases := []struct { name string requestMethod string expectAuthCall bool authCallReturn bool expectDBCall bool dbCallReturn error expectedStatusCode int expectedResponse string }{ {\u0026#34;method not allowed\u0026#34;, http.MethodGet, false, false, false, nil, 405, \u0026#34;method is not POST\\n\u0026#34;}, {\u0026#34;unauthenticated\u0026#34;, http.MethodPost, true, false, false, nil, 401, \u0026#34;unauthenticated\\n\u0026#34;}, {\u0026#34;db error\u0026#34;, http.MethodPost, true, true, true, errors.New(\u0026#34;failed to commit txn\u0026#34;), 500, \u0026#34;db error: failed to commit txn\\n\u0026#34;}, {\u0026#34;success\u0026#34;, http.MethodPost, true, true, true, nil, 201, \u0026#34;todo created\u0026#34;}, } for _, tc := range testCases { t.Run(tc.name, func(t *testing.T) { // Setup mocks … // Setup response recorder and request … if tc.expectAuthCall { auth.EXPECT().IsAuthenticated(testToken).Return(tc.authCallReturn) } if tc.expectDBCall { db.EXPECT().CreateTODO(\u0026amp;api.TODO{\u0026#34;task1\u0026#34;, \u0026#34;cat1\u0026#34;}).Return(tc.dbCallReturn) } ctrl.CreateTODO(w, r) resp := w.Result() assertEqual(t, tc.expectedStatusCode, resp.StatusCode) assertEqual(t, tc.expectedResponse, responseBody(resp)) }) } } Notice in the table:\nrequestMethod is really needed only for the “method not allowed” case but has to be present even for other test cases. expectAuthCall and expectDBCall are needed to set mock expectations (EXPECT()) for certain test cases. authCallReturn and dbCallReturn are needed by EXPECT() calls. Overall, trying to fit multiple dissimilar cases into a table-driven test has resulted in a more complicated test.\nContrarily, if you were to separate these test cases into separate tests, then granted, there will be more code, but the tests will be easier to understand. For instance, if the “method not allowed” case was its own separate test, it would look something like this:\nfunc TestController_CreateTODO_MethodNotAllowed(t *testing.T) { // Setup mocks … // Setup response recorder and request … ctrl.CreateTODO(w, r) resp := w.Result() assertEqual(t, 405, resp.StatusCode) assertEqual(t, \u0026#34;method is not POST\\n\u0026#34;, responseBody(resp)) } The test case itself is simple because no client calls are expected, but adding it as a part of the table-driven test made it more complicated.\nIf this HTTP handler doesn’t look complex enough, then understand that most HTTP handlers are way more sophisticated. For instance, they might use more clients (besides auth and db) for external services (e.g. cache). Also, EXPECT() calls might require different arguments for different test cases, which will then need to be part of the table - making the table bigger.\nConclusion Obvious to many, but not to some: Avoid writing a table-driven test where test cases have different testing setups.\nWorking sample code for everything here can be found in this repo: github.com/shivamMg/table-driven-tests-go.\nAll tests shown here can be found in this file: controller_test.go.\nThank you Avinash for reviewing the post\u0026rsquo;s draft.\n","permalink":"https://blog.shivammamgain.com/posts/2022/bad-table-driven-tests-go/","summary":"When to avoid table-driven tests","title":"Go: Bad table-driven tests"},{"content":"My older blog was at Blogger.com. All of my older posts can be found at shivammg.blogspot.com.\n","permalink":"https://blog.shivammamgain.com/posts/2022/older-blog/","summary":"Older blog at shivammg.blogspot.com","title":"Older Blog"}]